{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import en_core_web_sm\n",
    "from spacymoji import Emoji\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model Imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model Evaluation Metrics Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam tweets: 2333686\n",
      "Normal tweets: 7872\n",
      "Total tweets: 2341558\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "content_polluters_tweets_df = pd.read_csv('../Data/content_polluters_tweets_pp.csv')\n",
    "legitimate_users_tweets_df = pd.read_csv('../Data/legitimate_users_tweets_pp.csv')\n",
    "\n",
    "# Create a dataset of equal spam/not-spam tweets\n",
    "tweets_df = content_polluters_tweets_df.append(legitimate_users_tweets_df, ignore_index=True)\n",
    "content_polluters_tweets_df = tweets_df.head(len(content_polluters_tweets_df))\n",
    "legitimate_users_tweets_df = tweets_df.tail(len(legitimate_users_tweets_df))\n",
    "\n",
    "# Display dataset's statistics\n",
    "print(\"Spam tweets:\", len(content_polluters_tweets_df))\n",
    "print(\"Normal tweets:\", len(legitimate_users_tweets_df))\n",
    "print(\"Total tweets:\", len(tweets_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "def split(tweets_df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tweets_df['Tweet'], tweets_df['Spam'], test_size=0.2, random_state=0)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)\n",
    "    return X_train.str.lower(), y_train, X_val.str.lower(), y_val, X_test.str.lower(), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation model\n",
    "def evaluation_summary(description, predictions, true_labels):\n",
    "  print(\"Macro-averaged evaluation for: \" + description)\n",
    "  precision = precision_score(predictions, true_labels, average='macro')\n",
    "  recall = recall_score(predictions, true_labels, average='macro')\n",
    "  accuracy = accuracy_score(predictions, true_labels)\n",
    "  f1 = f1_score(predictions, true_labels, average='macro')\n",
    "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
    "  print(classification_report(predictions, true_labels, digits=3, zero_division = 0))\n",
    "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic grid search method to return best model hyperparameters for the best scoring iteration in macro F1 score\n",
    "def grid_search(pipeline, train_data, params):\n",
    "       \n",
    "    # Define grid search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=params, n_jobs=8, verbose=1, scoring='f1_macro', cv=2, error_score='raise')\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"Parameters:\")\n",
    "    print(params)\n",
    "    X_train, y_train = train_data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    return best_parameters\n",
    "\n",
    "# Define c_values parameter\n",
    "c_values = []\n",
    "for power in range(-3,6):\n",
    "  c_values.append(10**power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe('emoji', first=True)\n",
    "\n",
    "# Custom Tokenize\n",
    "def custom_tokenize(string):\n",
    "  tokens = list()\n",
    "  doc = nlp(string)\n",
    "  for token in doc:\n",
    "    # Ignore emojis, stop-words and numerical tokens\n",
    "    if not (token._.is_emoji or token.is_stop or token.like_num or token.like_url):\n",
    "      tokens.append(token)\n",
    "  return tokens\n",
    "\n",
    "# Custom Normalize\n",
    "def custom_normalize(tokens):\n",
    "  normalized_tokens = list()\n",
    "  for token in tokens:\n",
    "    # Lower token and lemmatize if not a pronoun\n",
    "    normalized = token.lemma_.lower().strip() if token.lemma_ != \"-PRON-\" else token.lower_\n",
    "    normalized_tokens.append(normalized)\n",
    "  return ' '.join(normalized_tokens)\n",
    "\n",
    "# Custom Tokenize and normalize\n",
    "def custom_tokenize_normalize(string):\n",
    "  return custom_normalize(custom_tokenize(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.2s\n",
      "Macro-averaged evaluation for: LR TF-IDF\n",
      "Classifier 'LR TF-IDF' has Acc=0.876 P=0.876 R=0.876 F1=0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.880     0.876     0.878      1598\n",
      "        True      0.873     0.877     0.875      1551\n",
      "\n",
      "    accuracy                          0.876      3149\n",
      "   macro avg      0.876     0.876     0.876      3149\n",
      "weighted avg      0.876     0.876     0.876      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1400  191]\n",
      " [ 198 1360]]\n"
     ]
    }
   ],
   "source": [
    "# Base Logistic Regression with TF-IDF vectorization\n",
    "basic_p_lr_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(n_jobs=-1, verbose=True)),\n",
    "],verbose=True)\n",
    "\n",
    "lr_tweets_df = content_polluters_tweets_df.tail(7872).append(legitimate_users_tweets_df.tail(7872), ignore_index=True)\n",
    "lr_X_train, lr_y_train, lr_X_val, lr_y_val, lr_X_test, lr_y_test = split(lr_tweets_df)\n",
    "\n",
    "basic_p_lr_tfidf_m = basic_p_lr_tfidf.fit(lr_X_train, lr_y_train)\n",
    "dump(basic_p_lr_tfidf_m, '../Models/Basic/_p_lr_tfidf_m.joblib')\n",
    "evaluation_summary(\"LR TF-IDF\", basic_p_lr_tfidf_m.predict(lr_X_test), lr_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['tfidf', 'lr']\n",
      "Parameters:\n",
      "{'tfidf__sublinear_tf': (True, False), 'lr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\n",
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   0.3s\n",
      "Best score: 0.824\n",
      "Best parameters set:\n",
      "\tlr__C: 100\n",
      "\ttfidf__sublinear_tf: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Set parameters dictionary\n",
    "lr_params = {\n",
    "   'tfidf__sublinear_tf': (True, False),\n",
    "   'lr__C': (c_values)\n",
    "}\n",
    "\n",
    "basic_p_lr_tfidf_params = grid_search(basic_p_lr_tfidf, (lr_X_val, lr_y_val), lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 2 of 2) Processing lr, total=   1.3s\n",
      "Macro-averaged evaluation for: LR TF-IDF\n",
      "Classifier 'LR TF-IDF' has Acc=0.906 P=0.906 R=0.906 F1=0.906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.907     0.906     0.907      1592\n",
      "        True      0.904     0.905     0.905      1557\n",
      "\n",
      "    accuracy                          0.906      3149\n",
      "   macro avg      0.906     0.906     0.906      3149\n",
      "weighted avg      0.906     0.906     0.906      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1443  148]\n",
      " [ 149 1409]]\n"
     ]
    }
   ],
   "source": [
    "best_p_lr_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(sublinear_tf=True)),\n",
    "    ('lr', LogisticRegression(n_jobs=-1, verbose=True, C=100)),\n",
    "],verbose=True)\n",
    "\n",
    "final_lr_X_train = lr_X_train.append(lr_X_val)\n",
    "final_lr_y_train = lr_y_train.append(lr_y_val)\n",
    "\n",
    "best_p_lr_tfidf_m = best_p_lr_tfidf.fit(final_lr_X_train, final_lr_y_train)\n",
    "dump(best_p_lr_tfidf_m, '../Models/Basic/p_lr_tfidf_m.joblib')\n",
    "evaluation_summary(\"LR TF-IDF\", best_p_lr_tfidf_m.predict(lr_X_test), lr_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "Macro-averaged evaluation for: KNN TF-IDF\n",
      "Classifier 'KNN TF-IDF' has Acc=0.695 P=0.699 R=0.807 F1=0.671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.399     0.995     0.570       638\n",
      "        True      0.998     0.619     0.764      2511\n",
      "\n",
      "    accuracy                          0.695      3149\n",
      "   macro avg      0.699     0.807     0.667      3149\n",
      "weighted avg      0.877     0.695     0.725      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 635  956]\n",
      " [   3 1555]]\n"
     ]
    }
   ],
   "source": [
    "# Base K-Nearest Neighbors with TF-IDF vectorization\n",
    "basic_p_knn_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "],verbose=True)\n",
    "\n",
    "knn_tweets_df = content_polluters_tweets_df.tail(7872).append(legitimate_users_tweets_df.tail(7872), ignore_index=True)\n",
    "knn_X_train, knn_y_train, knn_X_val, knn_y_val, knn_X_test, knn_y_test = split(knn_tweets_df)\n",
    "\n",
    "basic_p_knn_tfidf_m = basic_p_knn_tfidf.fit(knn_X_train, knn_y_train)\n",
    "dump(basic_p_knn_tfidf_m, '../Models/Basic/p_knn_tfidf_m.joblib')\n",
    "evaluation_summary(\"KNN TF-IDF\", basic_p_knn_tfidf_m.predict(knn_X_test), knn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['tfidf', 'knn']\n",
      "Parameters:\n",
      "{'tfidf__sublinear_tf': (True, False), 'knn__n_neighbors': [2, 5, 10], 'knn__weights': ('uniform', 'distance')}\n",
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "Best score: 0.788\n",
      "Best parameters set:\n",
      "\tknn__n_neighbors: 5\n",
      "\tknn__weights: 'distance'\n",
      "\ttfidf__sublinear_tf: True\n"
     ]
    }
   ],
   "source": [
    "# Set parameters dictionary\n",
    "knn_params = {\n",
    "   'tfidf__sublinear_tf': (True, False),\n",
    "   'knn__n_neighbors': ([2,5,10]),\n",
    "   'knn__weights': ('uniform', 'distance')\n",
    "}\n",
    "\n",
    "basic_p_knn_tfidf_params = grid_search(basic_p_knn_tfidf, (knn_X_val, knn_y_val), knn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=   0.0s\n",
      "Macro-averaged evaluation for: KNN TF-IDF\n",
      "Classifier 'KNN TF-IDF' has Acc=0.743 P=0.746 R=0.827 F1=0.727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.493     0.996     0.660       788\n",
      "        True      0.998     0.659     0.794      2361\n",
      "\n",
      "    accuracy                          0.743      3149\n",
      "   macro avg      0.746     0.827     0.727      3149\n",
      "weighted avg      0.872     0.743     0.760      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 785  806]\n",
      " [   3 1555]]\n"
     ]
    }
   ],
   "source": [
    "best_p_knn_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(sublinear_tf=True)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5, weights='distance')),\n",
    "],verbose=True)\n",
    "\n",
    "final_knn_X_train = knn_X_train.append(knn_X_val)\n",
    "final_knn_y_train = knn_y_train.append(knn_y_val)\n",
    "\n",
    "best_p_knn_tfidf_m = best_p_knn_tfidf.fit(final_knn_X_train, final_knn_y_train)\n",
    "dump(best_p_knn_tfidf_m, '../Models/p_knn_tfidf_m.joblib')\n",
    "evaluation_summary(\"KNN TF-IDF\", best_p_knn_tfidf_m.predict(knn_X_test), knn_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.2s\n",
      "[LibSVM][Pipeline] ............... (step 2 of 2) Processing svm, total=  56.4s\n",
      "Macro-averaged evaluation for: SVM TF-IDF\n",
      "Classifier 'SVM TF-IDF' has Acc=0.904 P=0.904 R=0.904 F1=0.904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.906     0.904     0.905      1596\n",
      "        True      0.901     0.904     0.903      1553\n",
      "\n",
      "    accuracy                          0.904      3149\n",
      "   macro avg      0.904     0.904     0.904      3149\n",
      "weighted avg      0.904     0.904     0.904      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1442  149]\n",
      " [ 154 1404]]\n"
     ]
    }
   ],
   "source": [
    "# Base Support Vector Machine with TF-IDF vectorization\n",
    "basic_p_svm_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC(probability=True,verbose=True)),\n",
    "],verbose=True)\n",
    "\n",
    "svm_tweets_df = content_polluters_tweets_df.tail(7872).append(legitimate_users_tweets_df.tail(7872), ignore_index=True)\n",
    "svm_X_train, svm_y_train, svm_X_val, svm_y_val, svm_X_test, svm_y_test = split(svm_tweets_df)\n",
    "\n",
    "basic_p_svm_tfidf_m = basic_p_svm_tfidf.fit(svm_X_train, svm_y_train)\n",
    "dump(basic_p_svm_tfidf_m, '../Models/basic_p_svm_tfidf_m.joblib')\n",
    "evaluation_summary(\"SVM TF-IDF\", basic_p_svm_tfidf_m.predict(svm_X_test), svm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['tfidf', 'svm']\n",
      "Parameters:\n",
      "{'tfidf__sublinear_tf': (True, False), 'svm__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000], 'svm__kernel': ('linear', 'poly', 'rbf', 'sigmoid')}\n",
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.1s\n",
      "[LibSVM][Pipeline] ............... (step 2 of 2) Processing svm, total=   5.6s\n",
      "Best score: 0.823\n",
      "Best parameters set:\n",
      "\tsvm__C: 10\n",
      "\tsvm__kernel: 'rbf'\n",
      "\ttfidf__sublinear_tf: True\n"
     ]
    }
   ],
   "source": [
    "# Set parameters dictionary\n",
    "svm_params = {\n",
    "   'tfidf__sublinear_tf': (True, False),\n",
    "   'svm__C': (c_values),\n",
    "   'svm__kernel': ('linear', 'poly', 'rbf', 'sigmoid')\n",
    "}\n",
    "\n",
    "basic_p_svm_tfidf_params = grid_search(basic_p_svm_tfidf, (svm_X_val, svm_y_val), svm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.3s\n",
      "[LibSVM][Pipeline] ............... (step 2 of 2) Processing svm, total= 3.9min\n",
      "Macro-averaged evaluation for: SVM TF-IDF\n",
      "Classifier 'SVM TF-IDF' has Acc=0.913 P=0.913 R=0.913 F1=0.913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.912     0.916     0.914      1584\n",
      "        True      0.915     0.911     0.913      1565\n",
      "\n",
      "    accuracy                          0.913      3149\n",
      "   macro avg      0.913     0.913     0.913      3149\n",
      "weighted avg      0.913     0.913     0.913      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1451  140]\n",
      " [ 133 1425]]\n"
     ]
    }
   ],
   "source": [
    "best_p_svm_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(sublinear_tf=True)),\n",
    "    ('svm', SVC(C=10, kernel='rbf', probability=True,verbose=True)),\n",
    "],verbose=True)\n",
    "\n",
    "\n",
    "final_svm_X_train = svm_X_train.append(svm_X_val)\n",
    "final_svm_y_train = svm_y_train.append(svm_y_val)\n",
    "\n",
    "best_p_svm_tfidf_m = best_p_svm_tfidf.fit(final_svm_X_train, final_svm_y_train)\n",
    "dump(best_p_svm_tfidf_m, '../Models/p_svm_tfidf_m.joblib')\n",
    "evaluation_summary(\"SVM TF-IDF\", best_p_svm_tfidf_m.predict(svm_X_test), svm_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing mnb, total=   0.0s\n",
      "Macro-averaged evaluation for: MNB TF-IDF\n",
      "Classifier 'MNB TF-IDF' has Acc=0.867 P=0.866 R=0.873 F1=0.866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.931     0.827     0.876      1790\n",
      "        True      0.802     0.919     0.856      1359\n",
      "\n",
      "    accuracy                          0.867      3149\n",
      "   macro avg      0.866     0.873     0.866      3149\n",
      "weighted avg      0.875     0.867     0.868      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1481  110]\n",
      " [ 309 1249]]\n"
     ]
    }
   ],
   "source": [
    "# Base Multinomial Naive Bayes with TF-IDF vectorization\n",
    "basic_p_mnb_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB()),\n",
    "],verbose=True)\n",
    "\n",
    "mnb_tweets_df = pd.concat([content_polluters_tweets_df.tail(7872), legitimate_users_tweets_df.tail(7872)], axis=0)\n",
    "mnb_X_train, mnb_y_train, mnb_X_val, mnb_y_val, mnb_X_test, mnb_y_test = split(mnb_tweets_df)\n",
    "\n",
    "basic_p_mnb_tfidf_m = basic_p_mnb_tfidf.fit(mnb_X_train, mnb_y_train)\n",
    "dump(basic_p_mnb_tfidf_m, '../Models/basic_p_mnb_tfidf_m.joblib')\n",
    "evaluation_summary(\"MNB TF-IDF\", basic_p_mnb_tfidf_m.predict(mnb_X_test), mnb_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['tfidf', 'mnb']\n",
      "Parameters:\n",
      "{'tfidf__sublinear_tf': (True, False), 'mnb__fit_prior': (True, False), 'mnb__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])}\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing mnb, total=   0.0s\n",
      "Best score: 0.817\n",
      "Best parameters set:\n",
      "\tmnb__alpha: 0.1\n",
      "\tmnb__fit_prior: True\n",
      "\ttfidf__sublinear_tf: True\n"
     ]
    }
   ],
   "source": [
    "# Set parameters dictionary\n",
    "mnb_params = {\n",
    "   'tfidf__sublinear_tf': (True, False),\n",
    "   'mnb__fit_prior': (True, False),\n",
    "   'mnb__alpha': (np.arange(0.1, 1.0, 0.1))\n",
    "}\n",
    "\n",
    "basic_p_mnb_tfidf_params = grid_search(basic_p_mnb_tfidf, (mnb_X_val, mnb_y_val), mnb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing mnb, total=   0.0s\n",
      "Macro-averaged evaluation for: MNB TF-IDF\n",
      "Classifier 'MNB TF-IDF' has Acc=0.893 P=0.893 R=0.894 F1=0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.918     0.876     0.897      1666\n",
      "        True      0.868     0.912     0.889      1483\n",
      "\n",
      "    accuracy                          0.893      3149\n",
      "   macro avg      0.893     0.894     0.893      3149\n",
      "weighted avg      0.894     0.893     0.893      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1460  131]\n",
      " [ 206 1352]]\n"
     ]
    }
   ],
   "source": [
    "best_p_mnb_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(sublinear_tf=True)),\n",
    "    ('mnb', MultinomialNB(alpha=0.1, fit_prior=True)),\n",
    "],verbose=True)\n",
    "\n",
    "\n",
    "final_mnb_X_train = mnb_X_train.append(mnb_X_val)\n",
    "final_mnb_y_train = mnb_y_train.append(mnb_y_val)\n",
    "\n",
    "best_p_mnb_tfidf_m = best_p_mnb_tfidf.fit(final_mnb_X_train, final_mnb_y_train)\n",
    "dump(best_p_mnb_tfidf_m, '../Models/p_mnb_tfidf_m.joblib')\n",
    "evaluation_summary(\"MNB TF-IDF\", best_p_mnb_tfidf_m.predict(mnb_X_test), mnb_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ................ (step 2 of 2) Processing dt, total=   1.5s\n",
      "Macro-averaged evaluation for: DT TF-IDF\n",
      "Classifier 'DT TF-IDF' has Acc=0.804 P=0.804 R=0.807 F1=0.804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.852     0.781     0.815      1737\n",
      "        True      0.755     0.834     0.793      1412\n",
      "\n",
      "    accuracy                          0.804      3149\n",
      "   macro avg      0.804     0.807     0.804      3149\n",
      "weighted avg      0.809     0.804     0.805      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1356  235]\n",
      " [ 381 1177]]\n"
     ]
    }
   ],
   "source": [
    "# Base Decision Tree with TF-IDF vectorization\n",
    "basic_p_dt_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "],verbose=True)\n",
    "\n",
    "dt_tweets_df = content_polluters_tweets_df.tail(7872).append(legitimate_users_tweets_df.tail(7872), ignore_index=True)\n",
    "dt_X_train, dt_y_train, dt_X_val, dt_y_val, dt_X_test, dt_y_test = split(dt_tweets_df)\n",
    "\n",
    "basic_p_dt_tfidf_m = basic_p_dt_tfidf.fit(dt_X_train, dt_y_train)\n",
    "dump(basic_p_dt_tfidf_m, '../Models/basic_p_dt_tfidf_m.joblib')\n",
    "evaluation_summary(\"DT TF-IDF\", basic_p_dt_tfidf_m.predict(dt_X_test), dt_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['tfidf', 'dt']\n",
      "Parameters:\n",
      "{'tfidf__sublinear_tf': (True, False), 'dt__criterion': ('gini', 'entropy'), 'dt__max_features': (None, 'auto', 'sqrt', 'log2')}\n",
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ................ (step 2 of 2) Processing dt, total=   0.0s\n",
      "Best score: 0.727\n",
      "Best parameters set:\n",
      "\tdt__criterion: 'entropy'\n",
      "\tdt__max_features: 'auto'\n",
      "\ttfidf__sublinear_tf: False\n"
     ]
    }
   ],
   "source": [
    "# Set parameters dictionary\n",
    "dt_params = {\n",
    "   'tfidf__sublinear_tf': (True, False),\n",
    "   'dt__criterion': ('gini', 'entropy'),\n",
    "   'dt__max_features': (None, 'auto', 'sqrt', 'log2')\n",
    "}\n",
    "\n",
    "basic_p_dt_tfidf_params = grid_search(basic_p_dt_tfidf, (dt_X_val, dt_y_val), dt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ................ (step 2 of 2) Processing dt, total=   0.1s\n",
      "Macro-averaged evaluation for: DT TF-IDF\n",
      "Classifier 'DT TF-IDF' has Acc=0.797 P=0.797 R=0.798 F1=0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.828     0.783     0.805      1683\n",
      "        True      0.766     0.814     0.789      1466\n",
      "\n",
      "    accuracy                          0.797      3149\n",
      "   macro avg      0.797     0.798     0.797      3149\n",
      "weighted avg      0.799     0.797     0.798      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1318  273]\n",
      " [ 365 1193]]\n"
     ]
    }
   ],
   "source": [
    "best_p_dt_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(sublinear_tf=False)),\n",
    "    ('dt', DecisionTreeClassifier(max_features='auto', criterion='entropy')),\n",
    "],verbose=True)\n",
    "\n",
    "\n",
    "final_dt_X_train = dt_X_train.append(dt_X_val)\n",
    "final_dt_y_train = dt_y_train.append(dt_y_val)\n",
    "\n",
    "best_p_dt_tfidf_m = best_p_dt_tfidf.fit(final_dt_X_train, final_dt_y_train)\n",
    "dump(best_p_dt_tfidf_m, '../Models/p_dt_tfidf_m.joblib')\n",
    "evaluation_summary(\"DT TF-IDF\", best_p_dt_tfidf_m.predict(dt_X_test), dt_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_down_tweet(string, normalize=True):\n",
    "    tokens = []\n",
    "    doc = nlp(string)\n",
    "    emojis = []\n",
    "    ats = []\n",
    "    hashtags = []\n",
    "    emoji_num = 0\n",
    "    nums = 0\n",
    "    stop_word_num = 0\n",
    "    for token in doc:\n",
    "        try:\n",
    "            if not token.like_url:\n",
    "                if token.prefix_ == '@':\n",
    "                    ats.append(token)\n",
    "                elif token.prefix_ == '#':\n",
    "                    hashtags.append(token)\n",
    "                elif token._.is_emoji:\n",
    "                    emoji_num += 1\n",
    "                    emojis.append(token)\n",
    "                elif token.like_num:\n",
    "                    nums += 1\n",
    "                elif token.is_stop:\n",
    "                    stop_word_num += 1\n",
    "                else:\n",
    "                    tokens.append(token)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    if normalize:\n",
    "        tokens = custom_normalize(tokens)\n",
    "    \n",
    "    return tokens, nums, emojis, emoji_num, stop_word_num, ats, hashtags\n",
    "\n",
    "def meta_tweets(df):\n",
    "# Extract URLs, @s, #s, emojis, numbers and stop-words\n",
    "# Count words, stop-words, numbers, emojis\n",
    "    meta_df = df[0:0]\n",
    "    for i in range(len(df)):\n",
    "        row = df[i:i+1]\n",
    "        tokens, nums, emojis, emoji_num, stop_word_num, ats, hashtags = break_down_tweet(row['Tweet'].iat[0])\n",
    "        row['Tokens'] = ''.join(tokens)\n",
    "        row['Numerical'] = nums\n",
    "        row['Emojis'] = [emojis]\n",
    "        row['Emoji count'] = emoji_num\n",
    "        row['Stop-word count'] = stop_word_num\n",
    "        row['@s'] = [ats]\n",
    "        row['#s'] = [hashtags]\n",
    "        meta_df = meta_df.append(row)\n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "def nlp_split(tweets_df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tweets_df, tweets_df['Spam'], test_size=0.2, random_state=0)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_polluters_tweets_df_copy = content_polluters_tweets_df.copy()\n",
    "legitimate_users_tweets_df_copy = legitimate_users_tweets_df.copy()\n",
    "\n",
    "meta_cp_tweets_df = meta_tweets(content_polluters_tweets_df_copy.tail(7872))\n",
    "meta_lu_tweets_df = meta_tweets(legitimate_users_tweets_df_copy.tail(7872))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Model with Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing ct, total=   0.1s\n",
      "[LibSVM][Pipeline] ............... (step 2 of 2) Processing svm, total=  14.4s\n",
      "Macro-averaged evaluation for: Advanced Model with Numerical Features\n",
      "Classifier 'Advanced Model with Numerical Features' has Acc=0.954 P=0.954 R=0.954 F1=0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.962     0.947     0.954      1617\n",
      "        True      0.945     0.961     0.953      1532\n",
      "\n",
      "    accuracy                          0.954      3149\n",
      "   macro avg      0.954     0.954     0.954      3149\n",
      "weighted avg      0.954     0.954     0.954      3149\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[1531   60]\n",
      " [  86 1472]]\n"
     ]
    }
   ],
   "source": [
    "adv_tweets_df = meta_cp_tweets_df.tail(7872).append(meta_lu_tweets_df.tail(7872), ignore_index=True)\n",
    "adv_X_train, adv_y_train, adv_X_val, adv_y_val, adv_X_test, adv_y_test = nlp_split(adv_tweets_df)\n",
    "adv_X_train = adv_X_train.append(adv_X_val)\n",
    "adv_y_train = adv_y_train.append(adv_y_val)\n",
    "\n",
    "numeric_features = [\"NumberOfFollowers\",\"NumberOfTweets\",\"LengthOfScreenName\",\"LengthOfDescriptionInUserProfile\",\"TimeDelta(Days)\",\"Numerical\",\"Emoji count\",\"Stop-word count\"]\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "                    # TFIDF Vectorization of custom tokenized tweet\n",
    "                    (\"tfidf\", TfidfVectorizer(sublinear_tf=True), 'Tokens'),\n",
    "                    # Numeric Features\n",
    "                    ('numeric', 'passthrough', numeric_features)\n",
    "                    ])\n",
    "\n",
    "adv_pipeline = Pipeline([\n",
    "    ('ct', column_transformer),\n",
    "    ('svm', SVC(C=10, kernel='rbf', probability=True,verbose=True)),\n",
    "],verbose=True)\n",
    "\n",
    "adv_model = adv_pipeline.fit(adv_X_train, adv_y_train)\n",
    "dump(adv_model, '../Models/Advanced/advanced_model.joblib')\n",
    "evaluation_summary('Advanced Model with Numerical Features', adv_pipeline.predict(adv_X_test), adv_y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "141244049137c618073c79afd0f9a58880087fb35bece71bcaf6735ec1c6597d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
